{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff3c55f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe10128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from keras.layers.core import Dense,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f4a195c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giorg\\OneDrive - Universit√† degli Studi di Milano-Bicocca\\Laurea Magistrale - Data Science\\directory_progetti\\deep-learning-video-classification\n"
     ]
    }
   ],
   "source": [
    "#path dove si trova il dataframe hmdb51\n",
    "path = Path.cwd()\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c48d39",
   "metadata": {},
   "source": [
    "Testing if cuda is on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bff241e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b802b407",
   "metadata": {},
   "source": [
    "# Spatial Data Generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27cab245",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/hmdb51'\n",
    "path_rowframes = './data/hmdb51/rawframes/'\n",
    "path_annotations = './data/hmdb51/annotations/'\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 64\n",
    "num_classes = 51\n",
    "\n",
    "num_frames_desired = 17     #number of frames per clip\n",
    "type_frame = 'img'          #img / flow_x / flow_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8eb40a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(list, num_frames_desired):\n",
    "    step = len(list) // (num_frames_desired)\n",
    "    #selected_frames = list(range(0, len(list), step))[:num_frames_desired]\n",
    "    sampled_list = list[0:len(list):step][:num_frames_desired]\n",
    "    return(sampled_list)\n",
    "\n",
    "def parse_image(filename):\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    return image\n",
    "\n",
    "def configure_for_performance(ds):\n",
    "    ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def find_paths(partition, type_frame, num_frames_desired):\n",
    "    if partition == 'train':\n",
    "        video_list = pd.read_csv(f'{path_annotations}/hmdb51_train_split_1_rawframes.txt', sep=\" \", header=None) #train\n",
    "        video_list.columns = [\"path\", \"num_frames_tot\", \"class\"]\n",
    "    elif partition == 'val':\n",
    "        video_list = pd.read_csv(f'{path_annotations}/hmdb51_val_split_1_rawframes.txt', sep=\" \", header=None) #test\n",
    "        video_list.columns = [\"path\", \"num_frames_tot\", \"class\"]\n",
    "    else:\n",
    "        raise Exception(\"invalid partition\")\n",
    "\n",
    "    #temp_path = video_list.loc[0]['path'] #da togliere!!!\n",
    "\n",
    "    paths = []\n",
    "    classes = []\n",
    "    for index, row in video_list.iterrows(): #da togliere [:1]\n",
    "        temp_path = row['path']                    #da rimuovere il commentato\n",
    "        frame_list = os.listdir(os.path.join(f'./{temp_path}'))\n",
    "\n",
    "        frame_list_type = [i for i in frame_list if i.startswith(f'{type_frame}')]\n",
    "\n",
    "        filename = sampling(frame_list_type, num_frames_desired)\n",
    "\n",
    "        paths.extend([os.path.join('.\\\\', temp_path, file) for file in filename])\n",
    "        temp = [row['class']] * 10\n",
    "        classes.extend(temp)\n",
    "\n",
    "    return(list(zip(paths, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb6384ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- create train set\n",
    "filenames = find_paths(partition='train', type_frame=type_frame, num_frames_desired=num_frames_desired)\n",
    "\n",
    "random.shuffle(filenames)\n",
    "\n",
    "zipped = [list(t) for t in zip(*filenames)]\n",
    "\n",
    "filenames = zipped[0]\n",
    "labels = zipped[1]\n",
    "\n",
    "filenames_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "images_ds = filenames_ds.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "ds = tf.data.Dataset.zip((images_ds, labels_ds))\n",
    "train_ds = configure_for_performance(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "71781ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35700\n"
     ]
    }
   ],
   "source": [
    "frame_number_train = len(filenames)\n",
    "print(frame_number_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75a40fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- create val test\n",
    "filenames = find_paths(partition='val', type_frame=type_frame, num_frames_desired=num_frames_desired)\n",
    "\n",
    "random.shuffle(filenames)\n",
    "\n",
    "zipped = [list(t) for t in zip(*filenames)]\n",
    "\n",
    "filenames = zipped[0]\n",
    "labels = zipped[1]\n",
    "\n",
    "filenames_ds = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "images_ds = filenames_ds.map(parse_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "labels_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
    "ds = tf.data.Dataset.zip((images_ds, labels_ds))\n",
    "val_ds = configure_for_performance(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5bdd738a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15300\n"
     ]
    }
   ],
   "source": [
    "frame_number_val = len(filenames)\n",
    "print(frame_number_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01190c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_per_epoch_train = frame_number_train // batch_size\n",
    "step_per_epoch_val = frame_number_val // batch_size\n",
    "print(step_per_epoch_train)\n",
    "print(step_per_epoch_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5e290",
   "metadata": {},
   "source": [
    "# Spatial Stream Finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d135974",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = './Models/spatial_model{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79af183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes, img_size=224):\n",
    "    input = tf.keras.layers.Input(shape=(img_size, img_size, 3))\n",
    "    model = tf.keras.applications.ResNet50(include_top=False, input_tensor=input, weights=\"imagenet\")\n",
    "\n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    output = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(input, output, name=\"EfficientNet\")\n",
    "    model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(num_classes)\n",
    "history_EfficientNet_spatial_stream = model.fit(train_ds, \n",
    "                                        validation_data = val_ds, \n",
    "                                        batch_size=batch_size, \n",
    "                                        epochs=20, \n",
    "                                        steps_per_epoch=step_per_epoch_train, \n",
    "                                        validation_steps=step_per_epoch_val,\n",
    "                                        callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6f6c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(img_height, img_width, 3))\n",
    "\n",
    "pretrained_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                                  input_tensor=input,\n",
    "                                                  pooling='avg',\n",
    "                                                  weights='imagenet')\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "resnet_model = Sequential()\n",
    "resnet_model.add(pretrained_model)\n",
    "\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "print(resnet_model.summary())\n",
    "\n",
    "# resnet_model.compile(optimizer = Adam(learning_rate=0.000001), loss = 'sparse_categorical_crossentropy', metrics = ['sparse_categorical_accuracy'])\n",
    "resnet_model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss = 'sparse_categorical_crossentropy', metrics = ['accuracy','sparse_categorical_accuracy'])\n",
    "\n",
    "history_ResNet_spatial_stream = resnet_model.fit(train_ds, \n",
    "                                        validation_data = val_ds, \n",
    "                                        epochs=20, \n",
    "                                        steps_per_epoch=step_per_epoch_train,\n",
    "                                        validation_steps=step_per_epoch_val,\n",
    "                                        callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2084da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig1 = plt.gcf()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.axis(ymin=0.2,ymax=1)\n",
    "plt.grid()\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train', 'validation'])\n",
    "plt.savefig('img.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DataExploration.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deepL37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "5f73b1806a9ec290aebb7f16dd5394fd2c9a0b8bec90a8791426b7ef5a3d9604"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
