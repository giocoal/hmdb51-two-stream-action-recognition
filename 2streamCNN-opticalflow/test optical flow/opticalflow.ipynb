{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6472\\3705838554.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Calculate dense optical flow by Farneback method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mflow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalcOpticalFlowFarneback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_gray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpyr_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwinsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoly_sigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Compute the magnitude and angle of the 2D vectors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mmagnitude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mangle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcartToPolar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Get a VideoCapture object from video and store it in vs\n",
    "vc = cv2.VideoCapture(\"April_09_brush_hair_u_nm_np1_ba_goo_0.avi\")\n",
    "# Read first frame\n",
    "ret, first_frame = vc.read()\n",
    "# Scale and resize image\n",
    "resize_dim = 600\n",
    "max_dim = max(first_frame.shape)\n",
    "scale = resize_dim/max_dim\n",
    "first_frame = cv2.resize(first_frame, None, fx=scale, fy=scale)\n",
    "# Convert to gray scale \n",
    "prev_gray = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "# Create mask\n",
    "mask = np.zeros_like(first_frame)\n",
    "# Sets image saturation to maximum\n",
    "mask[..., 1] = 255\n",
    "\n",
    "\n",
    "out = cv2.VideoWriter('video.avi',-1,1,(600, 600))\n",
    "\n",
    "while(vc.isOpened()):\n",
    "    # Read a frame from video\n",
    "    ret, frame = vc.read()\n",
    "    cv2.imshow('porcoddio', frame)\n",
    "    \n",
    "    # Convert new frame format`s to gray scale and resize gray frame obtained\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.resize(gray, None, fx=scale, fy=scale)\n",
    "\n",
    "    # Calculate dense optical flow by Farneback method\n",
    "    # https://docs.opencv.org/3.0-beta/modules/video/doc/motion_analysis_and_object_tracking.html#calcopticalflowfarneback\n",
    "    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, pyr_scale = 0.5, levels = 5, winsize = 11, iterations = 5, poly_n = 5, poly_sigma = 1.1, flags = 0)\n",
    "    # Compute the magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    # Set image hue according to the optical flow direction\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    # Set image value according to the optical flow magnitude (normalized)\n",
    "    mask[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    # Convert HSV to RGB (BGR) color representation\n",
    "    cv2.imshow('porcoddio1', mask)\n",
    "    rgb = cv2.cvtColor(mask, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    # Resize frame size to match dimensions\n",
    "    frame = cv2.resize(frame, None, fx=scale, fy=scale)\n",
    "    \n",
    "    # Open a new window and displays the output frame\n",
    "    dense_flow = cv2.addWeighted(frame, 1,rgb, 2, 0)\n",
    "    cv2.imshow(\"Dense optical flow\", dense_flow)\n",
    "    out.write(dense_flow)\n",
    "    # Update previous frame\n",
    "    prev_gray = gray\n",
    "    # Frame are read by intervals of 1 millisecond. The programs breaks out of the while loop when the user presses the 'q' key\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "cap = cv.VideoCapture(cv.samples.findFile(\"vtest.avi\"))\n",
    "ret, frame1 = cap.read()\n",
    "prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[..., 1] = 255\n",
    "while(1):\n",
    "    ret, frame2 = cap.read()\n",
    "    if not ret:\n",
    "        print('No frames grabbed!')\n",
    "        break\n",
    "    next = cv.cvtColor(frame2, cv.COLOR_BGR2GRAY)\n",
    "    flow = cv.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    mag, ang = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang*180/np.pi/2\n",
    "    hsv[..., 2] = cv.normalize(mag, None, 0, 255, cv.NORM_MINMAX)\n",
    "    bgr = cv.cvtColor(hsv, cv.COLOR_HSV2BGR)\n",
    "    cv.imshow('frame2', bgr)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif k == ord('s'):\n",
    "        cv.imwrite('opticalfb.png', frame2)\n",
    "        cv.imwrite('opticalhsv.png', bgr)\n",
    "    prvs = next\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def dense_optical_flow(method, video_path, params=[], to_gray=False):\n",
    "    # read the video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # Read the first frame\n",
    "    ret, old_frame = cap.read()\n",
    "\n",
    "    # crate HSV & make Value a constant\n",
    "    hsv = np.zeros_like(old_frame)\n",
    "    hsv[..., 1] = 255\n",
    "\n",
    "    # Preprocessing for exact method\n",
    "    if to_gray:\n",
    "        old_frame = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    while True:\n",
    "        # Read the next frame\n",
    "        ret, new_frame = cap.read()\n",
    "        frame_copy = new_frame\n",
    "        if not ret:\n",
    "            break\n",
    "        # Preprocessing for exact method\n",
    "        if to_gray:\n",
    "            new_frame = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Calculate Optical Flow\n",
    "        flow = method(old_frame, new_frame, None, *params)\n",
    "\n",
    "        # Encoding: convert the algorithm's output into Polar coordinates\n",
    "        mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "        # Use Hue and Saturation to encode the Optical Flow\n",
    "        hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "        hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Convert HSV image into BGR for demo\n",
    "        bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        cv2.imshow(\"frame\", frame_copy)\n",
    "        cv2.imshow(\"optical flow\", bgr)\n",
    "        k = cv2.waitKey(25) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "        old_frame = new_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_method(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    # params for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "    # Parameters for lucas kanade optical flow\n",
    "    lk_params = dict(\n",
    "        winSize=(15, 15),\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "    )\n",
    "    # Create some random colors\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    "    # Take first frame and find corners in it\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # calculate optical flow\n",
    "        p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "            old_gray, frame_gray, p0, None, **lk_params\n",
    "        )\n",
    "        # Select good points\n",
    "        good_new = p1[st == 1]\n",
    "        good_old = p0[st == 1]\n",
    "        # draw the tracks\n",
    "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "            a, b = new.ravel()\n",
    "            c, d = old.ravel()\n",
    "            mask = cv2.line(mask, (a, b), (c, d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame, (a, b), 5, color[i].tolist(), -1)\n",
    "        img = cv2.add(frame, mask)\n",
    "        cv2.imshow(\"frame\", img)\n",
    "        k = cv2.waitKey(25) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "        if k == ord(\"c\"):\n",
    "            mask = np.zeros_like(old_frame)\n",
    "        # Now update the previous frame and previous points\n",
    "        old_gray = frame_gray.copy()\n",
    "        p0 = good_new.reshape(-1, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lucaskanade\":\n",
    "video_path = \"Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\"\n",
    "lucas_kanade_method(video_path)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "video_path = \"Stabilized/Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\"\n",
    "lucas_kanade_method(video_path)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lucaskanade_dense\n",
    "method = cv2.optflow.calcOpticalFlowSparseToDense\n",
    "dense_optical_flow(method, \"Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\", to_gray=True)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "method = cv2.optflow.calcOpticalFlowSparseToDense\n",
    "dense_optical_flow(method, \"Stabilized/Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\", to_gray=True)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\"\n",
    "method = cv2.calcOpticalFlowFarneback\n",
    "params = [0.5, 3, 15, 3, 5, 1.2, 0]  # Farneback's algorithm parameters\n",
    "dense_optical_flow(method, video_path, params, to_gray=True)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "video_path = \"Stabilized/Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\"\n",
    "method = cv2.calcOpticalFlowFarneback\n",
    "params = [0.5, 3, 15, 3, 5, 1.2, 0]  # Farneback's algorithm parameters\n",
    "dense_optical_flow(method, video_path, params, to_gray=True)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RLOF\n",
    "video_path = \"Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\"\n",
    "method = cv2.optflow.calcOpticalFlowDenseRLOF\n",
    "dense_optical_flow(method, video_path)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "video_path = \"Stabilized/Increase_stride_length_by_running_stairs__working_step_over_action_speed_development_climb_stairs_f_cm_np1_le_med_1.avi\"\n",
    "method = cv2.optflow.calcOpticalFlowDenseRLOF\n",
    "dense_optical_flow(method, video_path)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module cv2.optflow in cv2:\n",
      "\n",
      "NAME\n",
      "    cv2.optflow\n",
      "\n",
      "FUNCTIONS\n",
      "    DenseRLOFOpticalFlow_create(...)\n",
      "        DenseRLOFOpticalFlow_create([, rlofParam[, forwardBackwardThreshold[, gridStep[, interp_type[, epicK[, epicSigma[, epicLambda[, ricSPSize[, ricSLICType[, use_post_proc[, fgsLambda[, fgsSigma[, use_variational_refinement]]]]]]]]]]]]]) -> retval\n",
      "        .   *    @param rlofParam see optflow::RLOFOpticalFlowParameter\n",
      "        .        *    @param forwardBackwardThreshold see setForwardBackward\n",
      "        .        *    @param gridStep see setGridStep\n",
      "        .        *    @param interp_type see setInterpolation\n",
      "        .        *    @param epicK see setEPICK\n",
      "        .        *    @param epicSigma see setEPICSigma\n",
      "        .        *    @param epicLambda see setEPICLambda\n",
      "        .        *    @param ricSPSize see setRICSPSize\n",
      "        .        *    @param ricSLICType see setRICSLICType\n",
      "        .        *    @param use_post_proc see setUsePostProc\n",
      "        .        *    @param fgsLambda see setFgsLambda\n",
      "        .        *    @param fgsSigma see setFgsSigma\n",
      "        .        *    @param use_variational_refinement see setUseVariationalRefinement\n",
      "    \n",
      "    DualTVL1OpticalFlow_create(...)\n",
      "        DualTVL1OpticalFlow_create([, tau[, lambda[, theta[, nscales[, warps[, epsilon[, innnerIterations[, outerIterations[, scaleStep[, gamma[, medianFiltering[, useInitialFlow]]]]]]]]]]]]) -> retval\n",
      "        .   @brief Creates instance of cv::DualTVL1OpticalFlow\n",
      "    \n",
      "    RLOFOpticalFlowParameter_create(...)\n",
      "        RLOFOpticalFlowParameter_create() -> retval\n",
      "        .\n",
      "    \n",
      "    SparseRLOFOpticalFlow_create(...)\n",
      "        SparseRLOFOpticalFlow_create([, rlofParam[, forwardBackwardThreshold]]) -> retval\n",
      "        .   *    @param rlofParam see setRLOFOpticalFlowParameter\n",
      "        .        *    @param forwardBackwardThreshold see setForwardBackward\n",
      "    \n",
      "    calcOpticalFlowDenseRLOF(...)\n",
      "        calcOpticalFlowDenseRLOF(I0, I1, flow[, rlofParam[, forwardBackwardThreshold[, gridStep[, interp_type[, epicK[, epicSigma[, epicLambda[, ricSPSize[, ricSLICType[, use_post_proc[, fgsLambda[, fgsSigma[, use_variational_refinement]]]]]]]]]]]]]) -> flow\n",
      "        .   @brief Fast dense optical flow computation based on robust local optical flow (RLOF) algorithms and sparse-to-dense interpolation scheme.\n",
      "        .    *\n",
      "        .    * The RLOF is a fast local optical flow approach described in @cite Senst2012 @cite Senst2013 @cite Senst2014\n",
      "        .    * and @cite Senst2016 similar to the pyramidal iterative Lucas-Kanade method as\n",
      "        .    * proposed by @cite Bouguet00. More details and experiments can be found in the following thesis @cite Senst2019.\n",
      "        .    * The implementation is derived from optflow::calcOpticalFlowPyrLK().\n",
      "        .    *\n",
      "        .    * The sparse-to-dense interpolation scheme allows for fast computation of dense optical flow using RLOF (see @cite Geistert2016).\n",
      "        .    * For this scheme the following steps are applied:\n",
      "        .    * -# motion vector seeded at a regular sampled grid are computed. The sparsity of this grid can be configured with setGridStep\n",
      "        .    * -# (optinally) errornous motion vectors are filter based on the forward backward confidence. The threshold can be configured\n",
      "        .    * with setForwardBackward. The filter is only applied if the threshold >0 but than the runtime is doubled due to the estimation\n",
      "        .    * of the backward flow.\n",
      "        .    * -# Vector field interpolation is applied to the motion vector set to obtain a dense vector field.\n",
      "        .    *\n",
      "        .    * @param I0 first 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType\n",
      "        .    * = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image.\n",
      "        .    * @param I1 second 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType\n",
      "        .    * = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image.\n",
      "        .    * @param flow computed flow image that has the same size as I0 and type CV_32FC2.\n",
      "        .    * @param rlofParam see optflow::RLOFOpticalFlowParameter\n",
      "        .    * @param forwardBackwardThreshold Threshold for the forward backward confidence check.\n",
      "        .    * For each grid point \\f$ \\mathbf{x} \\f$ a motion vector \\f$ d_{I0,I1}(\\mathbf{x}) \\f$ is computed.\n",
      "        .    * If the forward backward error \\f[ EP_{FB} = || d_{I0,I1} + d_{I1,I0} || \\f]\n",
      "        .    * is larger than threshold given by this function then the motion vector will not be used by the following\n",
      "        .    * vector field interpolation. \\f$ d_{I1,I0} \\f$ denotes the backward flow. Note, the forward backward test\n",
      "        .    *    will only be applied if the threshold > 0. This may results into a doubled runtime for the motion estimation.\n",
      "        .    * @param gridStep Size of the grid to spawn the motion vectors. For each grid point a motion vector is computed.\n",
      "        .    * Some motion vectors will be removed due to the forwatd backward threshold (if set >0). The rest will be the\n",
      "        .    * base of the vector field interpolation.\n",
      "        .    * @param interp_type interpolation method used to compute the dense optical flow. Two interpolation algorithms are\n",
      "        .    * supported:\n",
      "        .    * - **INTERP_GEO** applies the fast geodesic interpolation, see @cite Geistert2016.\n",
      "        .    * - **INTERP_EPIC_RESIDUAL** applies the edge-preserving interpolation, see @cite Revaud2015,Geistert2016.\n",
      "        .    * @param epicK see ximgproc::EdgeAwareInterpolator sets the respective parameter.\n",
      "        .    * @param epicSigma see ximgproc::EdgeAwareInterpolator sets the respective parameter.\n",
      "        .    * @param epicLambda see ximgproc::EdgeAwareInterpolator sets the respective parameter.\n",
      "        .    * @param ricSPSize  see ximgproc::RICInterpolator sets the respective parameter.\n",
      "        .    * @param ricSLICType see ximgproc::RICInterpolator sets the respective parameter.\n",
      "        .    * @param use_post_proc enables ximgproc::fastGlobalSmootherFilter() parameter.\n",
      "        .    * @param fgsLambda sets the respective ximgproc::fastGlobalSmootherFilter() parameter.\n",
      "        .    * @param fgsSigma sets the respective ximgproc::fastGlobalSmootherFilter() parameter.\n",
      "        .    * @param use_variational_refinement enables VariationalRefinement\n",
      "        .    *\n",
      "        .    * Parameters have been described in @cite Senst2012, @cite Senst2013, @cite Senst2014, @cite Senst2016.\n",
      "        .    * For the RLOF configuration see optflow::RLOFOpticalFlowParameter for further details.\n",
      "        .    * @note If the grid size is set to (1,1) and the forward backward threshold <= 0 that the dense optical flow field is purely\n",
      "        .    * computed with the RLOF.\n",
      "        .    *\n",
      "        .    * @note SIMD parallelization is only available when compiling with SSE4.1.\n",
      "        .    *\n",
      "        .    * @sa optflow::DenseRLOFOpticalFlow, optflow::RLOFOpticalFlowParameter\n",
      "    \n",
      "    calcOpticalFlowSF(...)\n",
      "        calcOpticalFlowSF(from, to, layers, averaging_block_size, max_flow[, flow]) -> flow\n",
      "        .   @overload\n",
      "        \n",
      "        \n",
      "        \n",
      "        calcOpticalFlowSF(from, to, layers, averaging_block_size, max_flow, sigma_dist, sigma_color, postprocess_window, sigma_dist_fix, sigma_color_fix, occ_thr, upscale_averaging_radius, upscale_sigma_dist, upscale_sigma_color, speed_up_thr[, flow]) -> flow\n",
      "        .   @brief Calculate an optical flow using \"SimpleFlow\" algorithm.\n",
      "        .   \n",
      "        .   @param from First 8-bit 3-channel image.\n",
      "        .   @param to Second 8-bit 3-channel image of the same size as prev\n",
      "        .   @param flow computed flow image that has the same size as prev and type CV_32FC2\n",
      "        .   @param layers Number of layers\n",
      "        .   @param averaging_block_size Size of block through which we sum up when calculate cost function\n",
      "        .   for pixel\n",
      "        .   @param max_flow maximal flow that we search at each level\n",
      "        .   @param sigma_dist vector smooth spatial sigma parameter\n",
      "        .   @param sigma_color vector smooth color sigma parameter\n",
      "        .   @param postprocess_window window size for postprocess cross bilateral filter\n",
      "        .   @param sigma_dist_fix spatial sigma for postprocess cross bilateralf filter\n",
      "        .   @param sigma_color_fix color sigma for postprocess cross bilateral filter\n",
      "        .   @param occ_thr threshold for detecting occlusions\n",
      "        .   @param upscale_averaging_radius window size for bilateral upscale operation\n",
      "        .   @param upscale_sigma_dist spatial sigma for bilateral upscale operation\n",
      "        .   @param upscale_sigma_color color sigma for bilateral upscale operation\n",
      "        .   @param speed_up_thr threshold to detect point with irregular flow - where flow should be\n",
      "        .   recalculated after upscale\n",
      "        .   \n",
      "        .   See @cite Tao2012 . And site of project - <http://graphics.berkeley.edu/papers/Tao-SAN-2012-05/>.\n",
      "        .   \n",
      "        .   @note\n",
      "        .      -   An example using the simpleFlow algorithm can be found at samples/simpleflow_demo.cpp\n",
      "    \n",
      "    calcOpticalFlowSparseRLOF(...)\n",
      "        calcOpticalFlowSparseRLOF(prevImg, nextImg, prevPts, nextPts[, status[, err[, rlofParam[, forwardBackwardThreshold]]]]) -> nextPts, status, err\n",
      "        .   @brief Calculates fast optical flow for a sparse feature set using the robust local optical flow (RLOF) similar\n",
      "        .   * to optflow::calcOpticalFlowPyrLK().\n",
      "        .   *\n",
      "        .   * The RLOF is a fast local optical flow approach described in @cite Senst2012 @cite Senst2013 @cite Senst2014\n",
      "        .    * and @cite Senst2016 similar to the pyramidal iterative Lucas-Kanade method as\n",
      "        .   * proposed by @cite Bouguet00. More details and experiments can be found in the following thesis @cite Senst2019.\n",
      "        .   * The implementation is derived from optflow::calcOpticalFlowPyrLK().\n",
      "        .   *\n",
      "        .   * @param prevImg first 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType\n",
      "        .   * = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image.\n",
      "        .   * @param nextImg second 8-bit input image. If The cross-based RLOF is used (by selecting optflow::RLOFOpticalFlowParameter::supportRegionType\n",
      "        .   * = SupportRegionType::SR_CROSS) image has to be a 8-bit 3 channel image.\n",
      "        .   * @param prevPts vector of 2D points for which the flow needs to be found; point coordinates must be single-precision\n",
      "        .   * floating-point numbers.\n",
      "        .   * @param nextPts output vector of 2D points (with single-precision floating-point coordinates) containing the calculated\n",
      "        .   * new positions of input features in the second image; when optflow::RLOFOpticalFlowParameter::useInitialFlow variable is true  the vector must\n",
      "        .   * have the same size as in the input and contain the initialization point correspondences.\n",
      "        .   * @param status output status vector (of unsigned chars); each element of the vector is set to 1 if the flow for the\n",
      "        .   * corresponding features has passed the forward backward check.\n",
      "        .   * @param err output vector of errors; each element of the vector is set to the forward backward error for the corresponding feature.\n",
      "        .   * @param rlofParam see optflow::RLOFOpticalFlowParameter\n",
      "        .   * @param forwardBackwardThreshold Threshold for the forward backward confidence check. If forewardBackwardThreshold <=0 the forward\n",
      "        .   *\n",
      "        .   * @note SIMD parallelization is only available when compiling with SSE4.1.\n",
      "        .   *\n",
      "        .   * Parameters have been described in @cite Senst2012, @cite Senst2013, @cite Senst2014 and @cite Senst2016.\n",
      "        .   * For the RLOF configuration see optflow::RLOFOpticalFlowParameter for further details.\n",
      "    \n",
      "    calcOpticalFlowSparseToDense(...)\n",
      "        calcOpticalFlowSparseToDense(from, to[, flow[, grid_step[, k[, sigma[, use_post_proc[, fgs_lambda[, fgs_sigma]]]]]]]) -> flow\n",
      "        .   @brief Fast dense optical flow based on PyrLK sparse matches interpolation.\n",
      "        .   \n",
      "        .   @param from first 8-bit 3-channel or 1-channel image.\n",
      "        .   @param to  second 8-bit 3-channel or 1-channel image of the same size as from\n",
      "        .   @param flow computed flow image that has the same size as from and CV_32FC2 type\n",
      "        .   @param grid_step stride used in sparse match computation. Lower values usually\n",
      "        .          result in higher quality but slow down the algorithm.\n",
      "        .   @param k number of nearest-neighbor matches considered, when fitting a locally affine\n",
      "        .          model. Lower values can make the algorithm noticeably faster at the cost of\n",
      "        .          some quality degradation.\n",
      "        .   @param sigma parameter defining how fast the weights decrease in the locally-weighted affine\n",
      "        .          fitting. Higher values can help preserve fine details, lower values can help to get rid\n",
      "        .          of the noise in the output flow.\n",
      "        .   @param use_post_proc defines whether the ximgproc::fastGlobalSmootherFilter() is used\n",
      "        .          for post-processing after interpolation\n",
      "        .   @param fgs_lambda see the respective parameter of the ximgproc::fastGlobalSmootherFilter()\n",
      "        .   @param fgs_sigma  see the respective parameter of the ximgproc::fastGlobalSmootherFilter()\n",
      "    \n",
      "    createOptFlow_DeepFlow(...)\n",
      "        createOptFlow_DeepFlow() -> retval\n",
      "        .   @brief DeepFlow optical flow algorithm implementation.\n",
      "        .   \n",
      "        .   The class implements the DeepFlow optical flow algorithm described in @cite Weinzaepfel2013 . See\n",
      "        .   also <http://lear.inrialpes.fr/src/deepmatching/> .\n",
      "        .   Parameters - class fields - that may be modified after creating a class instance:\n",
      "        .   -   member float alpha\n",
      "        .   Smoothness assumption weight\n",
      "        .   -   member float delta\n",
      "        .   Color constancy assumption weight\n",
      "        .   -   member float gamma\n",
      "        .   Gradient constancy weight\n",
      "        .   -   member float sigma\n",
      "        .   Gaussian smoothing parameter\n",
      "        .   -   member int minSize\n",
      "        .   Minimal dimension of an image in the pyramid (next, smaller images in the pyramid are generated\n",
      "        .   until one of the dimensions reaches this size)\n",
      "        .   -   member float downscaleFactor\n",
      "        .   Scaling factor in the image pyramid (must be \\< 1)\n",
      "        .   -   member int fixedPointIterations\n",
      "        .   How many iterations on each level of the pyramid\n",
      "        .   -   member int sorIterations\n",
      "        .   Iterations of Succesive Over-Relaxation (solver)\n",
      "        .   -   member float omega\n",
      "        .   Relaxation factor in SOR\n",
      "    \n",
      "    createOptFlow_DenseRLOF(...)\n",
      "        createOptFlow_DenseRLOF() -> retval\n",
      "        .\n",
      "    \n",
      "    createOptFlow_DualTVL1(...)\n",
      "        createOptFlow_DualTVL1() -> retval\n",
      "        .   @brief Creates instance of cv::DenseOpticalFlow\n",
      "    \n",
      "    createOptFlow_Farneback(...)\n",
      "        createOptFlow_Farneback() -> retval\n",
      "        .\n",
      "    \n",
      "    createOptFlow_PCAFlow(...)\n",
      "        createOptFlow_PCAFlow() -> retval\n",
      "        .   @brief Creates an instance of PCAFlow\n",
      "    \n",
      "    createOptFlow_SimpleFlow(...)\n",
      "        createOptFlow_SimpleFlow() -> retval\n",
      "        .\n",
      "    \n",
      "    createOptFlow_SparseRLOF(...)\n",
      "        createOptFlow_SparseRLOF() -> retval\n",
      "        .\n",
      "    \n",
      "    createOptFlow_SparseToDense(...)\n",
      "        createOptFlow_SparseToDense() -> retval\n",
      "        .\n",
      "\n",
      "DATA\n",
      "    GPC_DESCRIPTOR_DCT = 0\n",
      "    GPC_DESCRIPTOR_WHT = 1\n",
      "    INTERP_EPIC = 1\n",
      "    INTERP_GEO = 0\n",
      "    INTERP_RIC = 2\n",
      "    SR_CROSS = 1\n",
      "    SR_FIXED = 0\n",
      "    ST_BILINEAR = 1\n",
      "    ST_STANDART = 0\n",
      "\n",
      "FILE\n",
      "    (built-in)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.optflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "cv2.__version__\n",
    "cv2.cuda.getCudaEnabledDeviceCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #parser = ArgumentParser()\n",
    "    #parser.add_argument(\n",
    "    #    \"--algorithm\",\n",
    "    #    choices=[\"farneback\", \"lucaskanade\", \"lucaskanade_dense\", \"rlof\"],\n",
    "    #    required=True,\n",
    "    #    help=\"Optical flow algorithm to use\",\n",
    "    #)\n",
    "    #parser.add_argument(\n",
    "    #    \"--video_path\", default=\"videos/cat.mp4\", help=\"Path to the video\",\n",
    "    #)\n",
    "\n",
    "    video_path = \"videos/people.mp4\"\n",
    "    algorithm = \"lucaskanade_dense\"\n",
    "    \n",
    "    if algorithm == \"lucaskanade\":\n",
    "        lucas_kanade_method(video_path)\n",
    "    elif algorithm == \"lucaskanade_dense\":\n",
    "        method = cv2.optflow.calcOpticalFlowSparseToDense\n",
    "        dense_optical_flow(method, video_path, to_gray=True)\n",
    "    elif algorithm == \"farneback\":\n",
    "        method = cv2.calcOpticalFlowFarneback\n",
    "        params = [0.5, 3, 15, 3, 5, 1.2, 0]  # Farneback's algorithm parameters\n",
    "        dense_optical_flow(method, video_path, params, to_gray=True)\n",
    "    elif algorithm == \"rlof\":\n",
    "        method = cv2.optflow.calcOpticalFlowDenseRLOF\n",
    "        dense_optical_flow(method, video_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deepL37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f73b1806a9ec290aebb7f16dd5394fd2c9a0b8bec90a8791426b7ef5a3d9604"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
