{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://github.com/bashhike/video-action-recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporal_stream_data\n",
    "\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import pickle\n",
    "import optical_flow_prep as ofp\n",
    "import gc\n",
    "\n",
    "\n",
    "def stackOF(chunk,img_rows,img_cols,jobType):\n",
    "\tif jobType == 'train':\n",
    "\t\tpickleFile = '../dataset/temporal_train_data.pickle'\n",
    "\telse :\n",
    "\t\tpickleFile = '../dataset/temporal_test_data.pickle'\n",
    "\twith open(pickleFile,'rb') as f1:\n",
    "\t\ttemporal_train_data=pickle.load(f1)\n",
    "\n",
    "\tX_train,Y_train=ofp.stackOpticalFlow(chunk,temporal_train_data,img_rows,img_cols)\n",
    "\tgc.collect()\n",
    "\treturn (X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,os\n",
    "import pickle\n",
    "import optical_flow_prep as ofp\n",
    "import gc\n",
    "\n",
    "\n",
    "def stackOF(chunk,img_rows,img_cols,jobType):\n",
    "\tif jobType == 'train':\n",
    "\t\tpickleFile = '../dataset/temporal_train_data.pickle'\n",
    "\telse :\n",
    "\t\tpickleFile = '../dataset/temporal_test_data.pickle'\n",
    "\twith open(pickleFile,'rb') as f1:\n",
    "\t\ttemporal_train_data=pickle.load(f1)\n",
    "\n",
    "\tX_train,Y_train=ofp.stackOpticalFlow(chunk,temporal_train_data,img_rows,img_cols)\n",
    "\tgc.collect()\n",
    "\treturn (X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. https://github.com/wushidonguc/two-stream-action-recognition-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation optical flows\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import os.path\n",
    "import random\n",
    "import threading\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "\n",
    "def get_stacked_opt_flows(self, row):\n",
    "        output = []\n",
    "        opt_flow_dir_x = os.path.join(self.opt_flow_path, 'u', row[2])\n",
    "        opt_flow_dir_y = os.path.join(self.opt_flow_path, 'v', row[2])\n",
    "\n",
    "        # spatial parameters\n",
    "        # crop at center for validation\n",
    "        left = int((self.original_image_shape[0] - self.image_shape[0]) * 0.5)\n",
    "        top = int((self.original_image_shape[1] - self.image_shape[1]) * 0.5)\n",
    "        right = left + self.image_shape[0]\n",
    "        bottom = top + self.image_shape[1]\n",
    "            \n",
    "        # temporal parameters\n",
    "        total_frames = len(os.listdir(opt_flow_dir_x))\n",
    "        if total_frames - self.opt_flow_len + 1 < self.n_snip:\n",
    "            loop = True\n",
    "            strart_frame_window_len = 1\n",
    "        else:\n",
    "            loop = False\n",
    "            start_frame_window_len = (total_frames - self.opt_flow_len + 1) // self.n_snip # starting frame selection window length\n",
    "\n",
    "        # loop over snippets\n",
    "        for i_snip in range(self.n_snip):\n",
    "            if loop:\n",
    "                start_frame = i_snip % (total_frames - self.opt_flow_len + 1) + 1\n",
    "            else:\n",
    "                start_frame = int(0.5 * start_frame_window_len + 0.5) + start_frame_window_len * i_snip\n",
    "            # Get the optical flow stack\n",
    "            frames = range(start_frame, start_frame + self.opt_flow_len) # selected optical flow frames\n",
    "            opt_flow_stack = []\n",
    "            # loop over frames\n",
    "            for i_frame in frames:\n",
    "                # horizontal components\n",
    "                img = None # reset to be safe\n",
    "                img = cv2.imread(opt_flow_dir_x + '/frame' + \"%06d\"%i_frame + '.jpg', 0)\n",
    "                img = np.array(img)\n",
    "                img = img - np.mean(img) # mean substraction\n",
    "                img = img[top: bottom, left: right]\n",
    "                img = img / 255. # normalize pixels \n",
    "                opt_flow_stack.append(img)\n",
    "    \n",
    "                # vertical components\n",
    "                img2 = None # reset to be safe\n",
    "                img2 = cv2.imread(opt_flow_dir_y + '/frame' + \"%06d\"%i_frame + '.jpg', 0)\n",
    "                img2 = np.array(img2)\n",
    "                img2 = img2 - np.mean(img2) # mean substraction\n",
    "                img2 = img2[top: bottom, left: right]\n",
    "                img2 = img2 / 255. # normalize pixels \n",
    "                opt_flow_stack.append(img2)\n",
    "\n",
    "            opt_flow_stack = np.array(opt_flow_stack)\n",
    "            opt_flow_stack = np.swapaxes(opt_flow_stack, 0, 2)\n",
    "\n",
    "            output.append(opt_flow_stack)\n",
    "\n",
    "        output = np.array(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "'''\n",
    " def __init__(self, num_of_snip=1, opt_flow_len=10, image_shape=(224, 224), original_image_shape=(341, 256), class_limit=None):\n",
    "        \"\"\"Constructor.\n",
    "        opt_flow_len = (int) the number of optical flow frames to consider\n",
    "        class_limit = (int) number of classes to limit the data to.\n",
    "            None = no limit.\n",
    "        \"\"\"\n",
    "        self.opt_flow_len = opt_flow_len\n",
    "        self.num_of_snip = num_of_snip\n",
    "        self.class_limit = class_limit\n",
    "        self.image_shape = image_shape\n",
    "        self.original_image_shape = original_image_shape\n",
    "        self.opt_flow_path = os.path.join('/data', 'opt_flow')\n",
    "        \n",
    "        saved_model = None\n",
    "        class_limit = None  # int, can be 1-101 or None\n",
    "        num_of_snip = 1 # number of chunks used for each video \n",
    "        opt_flow_len = 10 # number of optical flow frames used\n",
    "        image_shape=(224, 224)\n",
    "        load_to_memory = False  # pre-load the sequences into memory\n",
    "        batch_size = 64\n",
    "        nb_epoch = 2222\n",
    "        name_str = None\n",
    "\n",
    "        # Get the data.\n",
    "        self.data_list = self.get_data_list()\n",
    "\n",
    "        # Get the classes.\n",
    "        self.classes = self.get_classes()\n",
    "\n",
    "        # Now do some minor data cleaning\n",
    "        self.data_list = self.clean_data_list()\n",
    "'''\n",
    "\n",
    "\n",
    "def stack_generator(self, batch_size, train_test, name_str=\"N/D\"):\n",
    "    \"\"\"Return a generator of optical frame stacks that we can use to train on. There are\n",
    "    a couple different things we can return:\n",
    "    \"\"\"\n",
    "    # Get the right dataset for the generator.\n",
    "    train, test = self.split_train_test()\n",
    "    data_list = train if train_test == 'train' else test\n",
    "\n",
    "    idx = 0\n",
    "\n",
    "    print(\"\\nCreating %s generator with %d samples.\\n\" % (train_test,\n",
    "        len(data_list)))\n",
    "\n",
    "    while 1:\n",
    "        idx += 1\n",
    "        print(\"Generator yielding batch No.%d\" % idx)\n",
    "        if(train_test == 'test'):\n",
    "            print(\"Validating for job: %s\" % name_str)\n",
    "        X, y = [], []\n",
    "\n",
    "        # Generate batch_size samples.\n",
    "        for _ in range(batch_size):\n",
    "            # Reset to be safe.\n",
    "            stack = []\n",
    "\n",
    "            # Get a random sample.\n",
    "            row = random.choice(data_list)\n",
    "\n",
    "            # Get the stacked optical flows from disk.\n",
    "            stack = self.get_stacked_opt_flows(row, train_test)\n",
    "\n",
    "            X.append(stack)\n",
    "            y.append(self.get_class_one_hot(row[1]))\n",
    "\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        y = np.squeeze(y)\n",
    "\n",
    "        yield X, y\n",
    "\n",
    "def get_stacked_opt_flows(self, row, train_test, crop='corner', val_aug='center'):\n",
    "    # crop options for training: corner, random\n",
    "    # augmentation options for testing: resize, center\n",
    "\n",
    "    opt_flow_stack = []                                                 # Definisco stack degli optical flows\n",
    "    opt_flow_dir_x = os.path.join(self.opt_flow_path, 'u', row[2])      # path optical flow x\n",
    "    opt_flow_dir_y = os.path.join(self.opt_flow_path, 'v', row[2])      # path optical flow y\n",
    "\n",
    "    # spatial parameters -> Data Augmentation\n",
    "    if train_test == 'train':\n",
    "        if crop == 'random':\n",
    "            # crop at center and four corners randomly for training\n",
    "            left, top = random.choice([[0, 0], [0, self.original_image_shape[1] - self.image_shape[1]], [self.original_image_shape[0] - self.image_shape[0], 0], [self.original_image_shape[0] - self.image_shape[0], self.original_image_shape[1] - self.image_shape[1]], [int((self.original_image_shape[0] - self.image_shape[0]) * 0.5), int((self.original_image_shape[1] - self.image_shape[1]) * 0.5)]])\n",
    "        else:\n",
    "            # random crop for training set\n",
    "            left = int((self.original_image_shape[0] - self.image_shape[0]) * random.random())\n",
    "            top = int((self.original_image_shape[1] - self.image_shape[1]) * random.random())\n",
    "    else:\n",
    "        # crop at center for validation\n",
    "        left = int((self.original_image_shape[0] - self.image_shape[0]) * 0.5)\n",
    "        top = int((self.original_image_shape[1] - self.image_shape[1]) * 0.5)\n",
    "    right = left + self.image_shape[0]\n",
    "    bottom = top + self.image_shape[1]\n",
    "\n",
    "    # temporal parameters\n",
    "    total_frames = len(os.listdir(opt_flow_dir_x))\n",
    "    '''\n",
    "    Definisco i parametri di stacking\n",
    "    total_frames = numero totale di frame del video\n",
    "    num_of_snip = 1 # number of chunks used for each video (1 di base)\n",
    "    opt_flow_len = 10 # number of optical flow frames used\n",
    "    \n",
    "    '''\n",
    "    win_len = (total_frames - self.opt_flow_len) // self.num_of_snip # starting frame selection window length  # selezione dei frame\n",
    "    if train_test == 'train':\n",
    "        start_frame = int(random.random() * win_len) + 1\n",
    "    else:\n",
    "        start_frame = int(0.5 * win_len) + 1\n",
    "    frames = [] # selected optical flow frames\n",
    "    for i in range(self.num_of_snip):\n",
    "        frames += range(start_frame + self.opt_flow_len * i, start_frame + self.opt_flow_len * (i + 1))\n",
    "\n",
    "    if train_test == 'train' and random.random() > 0.5: # flipping\n",
    "        flip = True\n",
    "    else:\n",
    "        flip = False\n",
    "\n",
    "    # loop over frames\n",
    "    for i_frame in frames:\n",
    "\n",
    "        # horizontal components\n",
    "        img = None # reset to be safe\n",
    "        img = cv2.imread(opt_flow_dir_x + '/frame' + \"%06d\"%(i_frame) + '.jpg', 0)\n",
    "        print(opt_flow_dir_x + '/frame' + \"%06d\"%(i_frame) + '.jpg')\n",
    "        img = np.array(img)\n",
    "        # mean substraction \n",
    "        img = img - np.mean(img)\n",
    "        if train_test == 'train' or val_aug == 'center':\n",
    "            # crop\n",
    "            img = img[left : right, top : bottom]\n",
    "        else:\n",
    "            #resize\n",
    "            img = cv2.resize(img, self.image_shape)\n",
    "        img = img / 255. # normalize pixels \n",
    "        if flip:\n",
    "            img = -img\n",
    "        opt_flow_stack.append(img)\n",
    "\n",
    "        # vertical components\n",
    "        img2 = None # reset to be safe\n",
    "        img2 = cv2.imread(opt_flow_dir_y + '/frame' + \"%06d\"%(i_frame) + '.jpg', 0)\n",
    "        # mean substraction \n",
    "        img2 = np.array(img2)\n",
    "        img2 = np.swapaxes(img2, 0, 1)\n",
    "        img2 = img2 - np.mean(img2)\n",
    "        if train_test == 'train' or val_aug == 'center':\n",
    "            # crop\n",
    "            img2 = img2[left : right, top : bottom]\n",
    "        else:\n",
    "            #resize\n",
    "            img2 = cv2.resize(img2, self.image_shape)\n",
    "        img2 = img2 / 255. # normalize pixels \n",
    "        opt_flow_stack.append(img2)\n",
    "\n",
    "    opt_flow_stack = np.array(opt_flow_stack)\n",
    "    opt_flow_stack = np.swapaxes(opt_flow_stack, 0, 1)\n",
    "    opt_flow_stack = np.swapaxes(opt_flow_stack, 1, 2)\n",
    "\n",
    "    # random horizontal flip for training sets\n",
    "    if flip:\n",
    "        opt_flow_stack = np.flip(opt_flow_stack, 0)\n",
    "\n",
    "    return opt_flow_stack\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('deepL37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f73b1806a9ec290aebb7f16dd5394fd2c9a0b8bec90a8791426b7ef5a3d9604"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
